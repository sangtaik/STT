{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import torch\n",
    "from unicode import join_jamos\n",
    "import re\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "import sys\n",
    "\n",
    "from transformers import (\n",
    "    Wav2Vec2CTCTokenizer,\n",
    "    Wav2Vec2FeatureExtractor,\n",
    "    Wav2Vec2Processor,\n",
    "    Wav2Vec2ForCTC,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServiceModel():\n",
    "    def __init__(self,base='jamo'):\n",
    "        self.base = base\n",
    "        if base=='jamo':\n",
    "            vocab = 'vocab_jamos.json'\n",
    "            model = 'jamo_base_model'\n",
    "            symspell_dict = \"symspell_jamo_dict.txt\"\n",
    "        elif base=='char':\n",
    "            vocab = 'vocab.json'\n",
    "            model = 'char_base_model'\n",
    "            symspell_dict = \"symspell_char_dict.txt\"\n",
    "        else:\n",
    "            sys.exit(\"'jamo' or 'char'\")\n",
    "            \n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "            feature_size=1,\n",
    "            sampling_rate=16000,\n",
    "            padding_value=0.0,\n",
    "            do_normalize=True,\n",
    "            return_attention_mask=True\n",
    "        )        \n",
    "        self.tokenizer = Wav2Vec2CTCTokenizer(\n",
    "            \"./Assets/\"+vocab,\n",
    "            unk_token=\"[UNK]\",\n",
    "            pad_token=\"[PAD]\",\n",
    "            word_delimiter_token=\"|\"\n",
    "        )\n",
    "        \n",
    "        self.processor = Wav2Vec2Processor(\n",
    "            feature_extractor=self.feature_extractor,\n",
    "            tokenizer=self.tokenizer\n",
    "        )\n",
    "        self.model = Wav2Vec2ForCTC.from_pretrained(\n",
    "            \"./Assets/\"+model, \n",
    "            attention_dropout=0.1,\n",
    "            hidden_dropout=0.1,\n",
    "            feat_proj_dropout=0.0,\n",
    "            mask_time_prob=0.05,\n",
    "            layerdrop=0.1,\n",
    "            ctc_loss_reduction=\"mean\", \n",
    "            pad_token_id=self.processor.tokenizer.pad_token_id,\n",
    "            vocab_size=len(self.processor.tokenizer)\n",
    "        )\n",
    "\n",
    "        self.sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "        \n",
    "        self.sym_spell.load_dictionary(symspell_dict, term_index=0, count_index=1, encoding='utf8')\n",
    "\n",
    "    # def voice_sep(sig):\n",
    "    #     sig = np.array(sig).flatten()\n",
    "    #     S_full, phase = librosa.magphase(librosa.stft(sig))\n",
    "    #     S_filter = librosa.decompose.nn_filter(S_full,\n",
    "    #                                     aggregate=np.median,\n",
    "    #                                     metric='cosine',\n",
    "    #                                     width=int(librosa.time_to_frames(2, sr=sr)))\n",
    "    #     S_filter = np.minimum(S_full, S_filter)\n",
    "    #     margin_v = 2\n",
    "    #     power = 2\n",
    "    #     mask_v = librosa.util.softmask(S_full - S_filter,\n",
    "    #                             margin_v * S_filter,\n",
    "    #                             power=power)\n",
    "    #     S_foreground = mask_v * S_full\n",
    "    #     y_foreground = librosa.istft(S_foreground * phase)\n",
    "    #     return y_foreground\n",
    "\n",
    "    \n",
    "    def prepare_dataset(self, batch):\n",
    "        \n",
    "        batch[\"input_values\"] = self.processor(batch[\"array\"], sampling_rate=16000).input_values[0]\n",
    "        \n",
    "        with self.processor.as_target_processor():\n",
    "            batch[\"labels\"] = self.processor(batch[\"text\"]).input_ids\n",
    "        return batch\n",
    "\n",
    "    def model_forward(self, array):\n",
    "        array = self.processor(array, sampling_rate=16000).input_values[0]\n",
    "        pred = self.model.forward(torch.from_numpy(array.reshape(1,-1)))\n",
    "        return pred\n",
    "\n",
    "    def pred_decode(self, pred):\n",
    "        pred_logits = pred['logits'].detach().numpy()\n",
    "        pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "        pred_str = self.processor.batch_decode(pred_ids)\n",
    "        return pred_str\n",
    "    \n",
    "    def char_one_shot(self, array):\n",
    "        pred = self.model_forward(array)\n",
    "        pred_str = self.pred_decode(pred)\n",
    "        return pred_str[0]\n",
    "    \n",
    "    def jamo_one_shot(self, array):\n",
    "        pred = self.model_forward(array)\n",
    "        pred_str = self.pred_decode(pred)\n",
    "        remove_pad_token = re.sub('<pad>','',pred_str[0])\n",
    "        suggestion = self.sym_spell.lookup_compound(remove_pad_token, max_edit_distance=1)\n",
    "        join_jamo = join_jamos(suggestion[0].term)\n",
    "        return join_jamo\n",
    "    \n",
    "    def one_shot(self, array):\n",
    "        base = self.base\n",
    "        if base=='jamo':\n",
    "            return self.jamo_one_shot(array)\n",
    "        elif base=='char':\n",
    "            return self.char_one_shot(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "service1 = ServiceModel(base=\"char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "service2 = ServiceModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(66976,)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "array,_ = librosa.load('./Assets/test_data.wav',16000)\n",
    "print(type(array))\n",
    "print(array.shape)\n",
    "print(array.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ServiceModel : 보 있는 영상 정지 시작 꺼줘\n"
     ]
    }
   ],
   "source": [
    "print('ServiceModel :',service1.char_one_shot(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ServiceV2 : 보 있는 영상 정지시켜 줘\n"
     ]
    }
   ],
   "source": [
    "print('ServiceV2 :',service2.jamo_one_shot(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('STT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19631f30805cf65d5465564d75f0fe7c05dee5c1f7be198222dbe754da644e52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
